---
title: 待办及进度
date: 2017-06-02 15:15:46
categories: 实验记录
tags:
description: 人脸识别实验记录
---
# step1:Mirror face相关

| Model              | PCA Size | Threshold | Score  |
| ------------------ | -------- | --------- | ------ |
| Mirror             | 192      | 0.64      | 99.42% |
| Mirror Concat      | 192      | 0.65      | 99.42% |
| Mirror Add/Average | 184      | 0.64      | 99.47% |
| Mirror Max         | 144      | 0.65      | 99.43% |
| Mirror Min         | 168      | 0.65      | 99.48% |
| Mirror Avg+min     | 168      | 0.65      | 99.45% |

# step2:单眼Patch model

| eye_width | num      | eye_width | num    |
| --------- | -------- | --------- | ------ |
| 0~10      | 14       | 90~100    | 8,5674 |
| 10~20     | 3329     | 100~110   | 2,9481 |
| 20~30     | 21,3675  | 110~120   | 9051   |
| 30~40     | 45,1416  | 120~130   | 2894   |
| 40~50     | 49,1913  | 130~140   | 932    |
| 50~60     | 72,8911  | 140~150   | 279    |
| 60~70     | 137,9232 | 150~160   | 86     |
| 70~80     | 128,7442 | 160~170   | 14     |
| 80~90     | 30,9026  | 170~180   | 6      |

## 问题

1.对于人脸关键点数据中，[eye_left_x,eye_left_y,eye_right_x,eye_right_y...],在进行眼睛宽度估算时，利用eye_width=(eye_right_x-eye_elft_x)*0.78,所以crop后左眼的最左边的坐标公式为eye_left_x-0.5*eye_width，有一种情况没考虑到就是eye_left_x小于0.5*eye_width，所以要加一个判断语句
```
if eye_width*0.5>eye_left_x:
            eye_width=eye_left_x*2
```
导致眼睛宽度估算分布就不太准确，最终导致在mscelebv1_crop数据上，最终符合要求的只有731750张

重新生成眼睛宽度估算文件，其分布如下

| eye_width | num      | eye_width | num  |
| --------- | -------- | --------- | ---- |
| 0~10      | 1,8975   | 100~110   | 98   |
| 10~20     | 71,3760  | 110~120   | 17   |
| 20~30     | 126,4102 | 120~130   | 3    |
| 30~40     | 226,4348 | 130~140   | 0    |
| 40~50     | 59,3351  | 140~150   | 0    |
| 50~60     | 10,6502  | 150~160   | 0    |
| 60~70     | 2,4588   | 160~170   | 1    |
| 70~80     | 5592     | 170~180   | 0    |
| 80~90     | 1588     | 180~190   | 8    |
| 90~100    | 421      | 190~200   | 21   |



2.tripletloss在100次迭代时，loss=nan，原因是初始化的base_lr过大，调小即可
3.test的accuracy一直为0：想到了在清洗数据的时候，有的人物并没有参与，也就是最开始直接用小蔓师兄的标签不行，最后一层的输出不等于我现在数据中的样本类别数。。得自己重新生成，首先要将空目录删除，确定有多少类别，然后label从0开始重新生成。
最后发现我的类别应该是90481.而最后一个全连接层的num_output=90526

<u>17个小时，迭代12万次，26.5%的准确率，loss=5.5。</u>



# step3:双眼patch model

生成双眼宽度估算文件，其分布如下

| eye_width | num      | eye_width | num     | eye_width | num  |
| --------- | -------- | --------- | ------- | --------- | ---- |
| 0~10      | 30       | 100~110   | 18,8771 | 200~210   | 383  |
| 10~20     | 5888     | 110~120   | 8,8508  | 210~220   | 196  |
| 20~30     | 11,4595  | 120~130   | 4,6243  | 220~230   | 100  |
| 30~40     | 35,5451  | 130~140   | 2,4982  | 230~240   | 52   |
| 40~50     | 42,6729  | 140~150   | 1,2749  | 240~250   | 33   |
| 50~60     | 49,1312  | 150~160   | 6714    | 250~260   | 15   |
| 60~70     | 69,0394  | 160~170   | 3413    | 260~270   | 3    |
| 70~80     | 104,9353 | 170~180   | 1909    | 270~280   | 2    |
| 80~90     | 100,6618 | 180~190   | 1091    | 280~290   | 0    |
| 90~100    | 47,7219  | 190~200   | 622     | 290~300   | 0    |

筛选crop后，宽度在20~130区间的图片，共90523个类别，4932655张。

train.txt：3982004 

val.txt：950661 

<u>18万次迭代之后，准确率只有66%左右。</u>



# step4:crop对齐后的图片的眼睛，训练单眼模型

数据集大小：5044507(90525个类)（"/home/yf/caffe-rc5-triplet/examples/triplet-face/clean.txt"，"/home/yf/data/msclean"）

       "ref_points": [
       		30.2946, 51.6963, 
            65.5318, 51.5014, 
            48.0252, 71.7366,
            33.5493, 92.3655, 
            62.7299, 92.2041
        ]
    
    
         eye_width=(ref_points[2]-ref_points[0])*0.8
            eye_height=eye_width
            x1=ref_points[0]-0.5*eye_width=16
            x2=ref_points[0]+0.5*eye_width=44
            y1=ref_points[1]-0.5*eye_height=37
            y2=ref_points[1]+0.5*eye_height=65
train:4071324 张

val:973183张



# step5:crop对齐后的图片的眼睛，训练双眼模型

数据集大小：5044507(90525个类)（"/home/yf/caffe-rc5-triplet/examples/triplet-face/clean.txt"，"/home/yf/data/msclean"）



       "ref_points": [
       	30.2946, 51.6963, 
        65.5318, 51.5014, 
        48.0252, 71.7366,
        33.5493, 92.3655, 
        62.7299, 92.2041
    ]
         eye_width=(ref_points[2]-ref_points[0])*0.8
        eye_height=eye_width
        x1=ref_points[0]-0.5*eye_width=16
        x2=ref_points[2]+0.5*eye_width=79
        y1=ref_points[1]-0.5*eye_height=37
        y2=ref_points[1]+0.5*eye_height=65
<u>迭代16万次，精度为72.73%，loss=2.52</u>

<u>在lfw上测试，精度最高达到77.04%</u>

# step6:Center face+dropout+finetune on softmax

在msclean测试集上达到93.53% 

| Model                             | PCA_Size | Threshold | Score  |
| :-------------------------------- | -------- | --------- | ------ |
| dropcenter                        | 168      | 0.64      | 99.42% |
| dropcenter_mirror                 | 136      | 0.64      | 99.38% |
| dropcenter +dropcenter_mirror+Min | 128      | 0.64      | 99.45% |
| dropcenter+dropcenter_mirror+ Add | 128      | 0.64      | 99.45% |
| center +dropcenter +Min           | 400      | 0.64      | 99.40% |
| centermirror+dropcenter+Min       | 128      | 0.64      | 99.45% |
| centermirror+dropcenter+Add       | 160      | 0.64      | 99.43% |
| centermirror+dropcenter+Max       | 160      | 0.64      | 99.43% |
| centermirror+dropcenter+Concate   | 192      | 0.65      | 99.47% |

| Model                                    | PCA Size | Threshold | Score  |
| ---------------------------------------- | -------- | --------- | ------ |
| center_min_mirror+dropcenter+Concate     | 192      | 0.65      | 99.47% |
| center_min_mirror+dropcenter+Min         | 128      | 0.65      | 99.42% |
| center_min_mirror+dropcenter+Add         | 136      | 0.64      | 99.47% |
| eye_model                                | 160      | 0.57      | 77.04% |
| eyemodel+center+Con                      | 208      | 0.66      | 74.80% |
| 三模型                                      |          |           |        |
| center+center_min_mirror+dropoutcenter+Concate | 128      | 0.65      | 99.43% |
| center+softmax+dropoutcenter+Concate     | 168      | 0.66      | 99.43% |
| center+softmax+dropoutcenter+Add         | 496      | 0.65      | 99.42% |





# step7:balance

## step7.1:减小过采样的数量，防止过拟合

对/home/yf/data/clean.txt中每种类别进行统计各有多少个数：

| 每种类别包含图片张数 | 类别数   | 每种类别包含图片张数 | 类别数   |
| ---------- | ----- | ---------- | ----- |
| <10        | 1213  | 10~20      | 11617 |
| 20~30      | 10868 | 30~40      | 9692  |
| 40~50      | 9020  | 50~60      | 8426  |
| 60~70      | 8443  | 70~80      | 8783  |
| 80~90      | 8762  | 90~100     | 7317  |
| 100~110    | 4277  | 110~120    | 1753  |
| 120~130    | 354   |            |       |

类别总数共90525。由上图可知，类别严重不均衡，之前处理类别不均衡的方法主要是欠抽样和过抽样结合，对于多数类样本丢弃一部分样本，对于少数类样本复制生成，最后的训练数据分布如下：

| 每种类别包含图片张数 | 类别数   | 每种类别包含图片张数 | 类别数   |
| ---------- | ----- | ---------- | ----- |
| 70~80      | 3673  | 80~90      | 19068 |
| 90~100     | 27069 | 100~110    | 40715 |

由于少数类占了大多数，但是重复太多，可能导致过拟合问题，于是将每个类别的图片张数减去30，重新生成balance的训练数据，并训练模型。

<u>迭代17万次后，msdata测试集上准确率达到92.28%，loss=0.27</u>

<u>lfw上精度为99.18%</u>

<u>mirror:99.27%</u>

<u>add:99.27%</u>

## step7.2:EasyEmsemble法均衡类别

step7.1的方法属于欠抽样和过抽样结合：

- 对于欠抽样算法，将多数类样本删除有可能会导致分类器**丢失有关多数类的重要信息**。
- 对于过抽样算法，虽然只是简单地将复制后的数据添加到原始数据集中，且某些样本的多个实例都是“**并列的**”，但这样也可能会导致分类器学习出现**过拟合现象**，对于同一个样本的多个复本产生多个规则条例，这就使得**规则过于具体化**；虽然在这种情况下，分类器的训练精度会很高，但在位置样本的分类性能就会非常不理想。

**EasyEnsemble 核心思想是：**

- 首先通过从多数类中**独立随机**抽取出若干子集

- 将每个子集与少数类数据**联合**起来**训练**生成多个基分类器

- 最终将这些基分类器**组合形成**一个集成学习系统

  设立一个阈值50，对于类别样本数超过50的，将其分写到两个不同的文件；对于类别样本数不超过50的，利用过采样进行增添，所以最终得到两个有交集的训练集A,B，两个训练集的样本数都是

  90525*50=4526250

<u>训练两个model，然后提取特征，对特征进行融合。</u>



| Model(acc/loss)                          | Pca Size | Threshold | Score  |
| ---------------------------------------- | -------- | --------- | ------ |
| model1(90.75%/0.41)                      | 176      | 0.64      | 99.05% |
| model1(92.14%/0.26)                      | 200      | 0.62      | 99.28% |
| model1(92.14%/0.26) Mirror               | 280      | 0.63      | 99.32% |
| model1(92.14%/0.26) Add Mirror           | 128      | 0.65      | 99.30% |
| model2(92.56%/0.41)                      | 128      | 0.64      | 99.27% |
| model2(92.56%/0.41) Mirror               | 192      | 0.63      | 99.35% |
| model2(92.56%/0.41) Add Mirror           | 192      | 0.64      | 99.32% |
| model1 add model2                        | 152      | 0.64      | 99.33% |
| model1 mirror add model2 mirror          | 136      | 0.65      | 99.37% |
| model1 add model2 mirror                 | 152      | 0.64      | 99.37% |
| model1_add_mirror add model2_add_mirror  | 152      | 0.64      | 99.38% |
| model1_add_mirror concate model2_add_mirror | 128      | 0.65      | 99.32% |
| model1 mirror min model2 mirror          | 168      | 0.64      | 99.37% |



# step8:UMDFaces

对UMDFaces数据集进行人脸对齐处理

batch1:175,534(3554类)

batch2:115,126(2590类)

batch3:77,228(2133类)

frames:3,735,475(3106类)

提取4个数据集的类别名称，经过处理分析后发现frames的类别属于batch1类别的子集，将3个batch与frames的数据集整合到一个数据集下，因为当静态图片和视频帧进行结合后训练的模型往往既能兼顾个体之间的差异（静态图片特征）也能学习到同一个个体的姿态变化（视频帧特征），要注意的一点就是对于frames和batch1中同一个类别的要放在一个目录下，并重新生成类别标签。

数据总量:4103363(8276个类别)

数据整理已经完成，接下来是在这个数据集上进行metric learning的训练。

train:3286012
val:817351

# step9:Megaface测试

| Model                           | Dataset            | Score(Megaface/LFW) |
| ------------------------------- | ------------------ | ------------------- |
| center-face                     | FaceScrub Set1/LFW | 67.32%/99.42%       |
| balance-reduced                 | FaceScrub Set1/LFW | 70.99%/99.18%       |
| easyensemble                    | FaceScrub Set1     | 73.91%/99.33%       |
| easyensemble  concat addmirror  | FaceScrub Set1     | 74.21%/99.37%       |
| balance-cent-soft               | FaceScrub Set1/LFW | 74.47%/99.33%       |
| balance-cent-soft concat mirror | FaceScrub Set1     | 75.65%              |

## step9.1:Megaface测试（续）

| Model                                    | Dataset                 | Score(Megaface/LFW) |
| ---------------------------------------- | ----------------------- | ------------------- |
| Dropout_center Concat mirror             | FaceScrub Set1/LFW      | 69.34%/99.47%       |
| normface easyensemble model1 Concart mirror | FaceScrub Set1/LFW      | 70.32%              |
| normface easyensemble 2models Concat mirror | FaceScrub Set1          | 70.49%              |
| balance concat mirror                    | FaceScrub(matlab_mtcnn) | 78.84%              |
| easyensemble concat addmirror            | FaceScrub(matlab_mtcnn) | 75.92%              |
| jitter_center_iter_190000 concat mirror  | FaceScrub(matlab_mtcnn) | 77.69%              |
| jitter_softmax_iter_180000 concat mirror | FaceScrub(matlab_mtcnn) | 83.13%              |
| jitter_softmax_iter_180000 only mirror   | FaceScrub(matlab_mtcnn) | 82.08%              |
| jitter_softmax_iter_180000 add mirror    | FaceScrub(matlab_mtcnn) | 82.87%              |
| jitter_softmax_iter_184000 concat mirror | FaceScrub(matlab_mtcnn) | 83.16%              |
| jitter_softmax_iter_180000 concat mirror | FaceScrub(python_mtcnn) | 78.33%              |
| jitter_softmax_iter_184000 concat mirror(matlab align) | FaceScrub(matlab_mtcnn) | 79.05%              |
| normface_jitter_iter_124000 concat mirror(python align) | FaceScrub(python_mtcnn) | 76.50%              |
| normface_jitter_iter124000 cancat mirror(python align) | FaceScrub(matlab_mtcnn) | 78.92%              |



# step 10:MTCNN(matlab)人脸检测及对齐

## step 10.1：对齐Megaface和FaceScrub

主要是Megaface数据集（1028062张）,FaceScrub数据集(91712张)，其中FaceScrub数据集中通过mtcnn（/home/yf/align/align_megaface.m）检测到的有89751张，剩余的1961张需要利用数据集中提供的3个关键点进行对齐，首先需要获取未检测到的图片的路径，然后利用python 脚本(/home/yf/megaface/devkit/templatelists/analysis/analysis_json.py)解析对应的存储该图片中人脸关键点的json文件，最后在利用matlab脚本(/home/yf/align/for_not_detect/align_megaface.m)进行批量对齐。Megaface数据集中未检测到的数据集同样处理。

**问题**：

在进行了41万次对齐后，出现了imread的错误，然后将从目录读取路径改成了从存储图片路径的文件中(/home/yf/megaface/tests/MegaFace_align_list_image.txt)直接获取路径，并输出每次进行处理的文件名，重新进行对齐操作，然后重现了这个错误，最后比对MegaFace_align_list_image.txt的下一张图片，发现有张图片是输入为空的。

## step 10.2:对齐msceleb数据

重新对齐msceleb数据集用于训练。

# step 11:Normface训练

Normface(paper:[NormFace: L2 Hypersphere Embedding for Face Verification](https://arxiv.org/pdf/1704.06369.pdf))

## step 11.1:训练EasyEnsemble模型

model1在测试集上的准确率为92.88%，model2在测试集上的准确率为92.85%。

暂时只测了单个的model1 concate mirror在Megaface(还是原始python版mtcnn对齐的)上的准确率只有70.32%。下周继续测试两个模型的效果。

## step 11.2:训练Balance模型

刚生成完训练的数据集，下周开始训练。

# step 12:Image Jitter

对图片增加随机扰动，包括缩放、角度变换、镜像操作，主要还是msceleb数据集(/home/yf/data/msclean)上进行，由于该数据集类别不均衡，所以对于样本数较少的类别可以采用这种办法增加样本容量。最终将每个类别的样本数控制在80~160之间。

10240892

train:9257534

val:983342

正在生成训练的数据集lmdb。

jitter_center_iter_190000 concat mirror  FaceScrub(matlab_mtcnn)  77.69%  

jitter_softmax_iter_180000 concat mirror  FaceScrub(matlab_mtcnn)  83.18%

jitter_softmax_iter_180000 only mirror  FaceScrub(matlab_mtcnn)  82.08%

jitter_softmax_iter_180000 add mirror  FaceScrub(matlab_mtcnn)  82.87%

jitter_softmax_iter_184000 concat mirror  FaceScrub(matlab_mtcnn)  83.16%



# step 13:Gender test

### 1.0

VGG16在lfw上准确率90.04%，在imdb(15590测试样本)上准确率90.92%

model training:female(69847),male(86061)

train:124728

val:15590

test:15590

### 2.0

网络：AlexNet 在清理后的数据集上，迭代29500次后，训练准确率为98.16%，loss=0.55

在测试集上达到98.11%（15127/15418)





# Todo1

- [x] Create umdfaces-->lmdb
- [x] EasyEnsemble train and test
- [x] Use matcaffe for metric learning
- [ ] Megaface test
      - - [x] center face
        - [x] balance-cent-soft
        - [x] reduced
        - [x] mirror or concatenate
        - [x] EasyEnsemble


- [x] Paper reading:One-shot face recognition by promoting underrepresented classes

      ​


# Todo2

- [ ] jitter model training(softmax first)

- [ ] balance model retrain on normface(include center loss)

- [ ] aligned by matlab_mtcnn megaface(balance model 75.65% version)

- [ ] gender classfication model training

      - check the dataset (detect and crop by matlab_mtcnn)
    
      - generate lmdb
    
      - choose a model(ResNet?)
    
        ​

### 参考链接

[happynear-face-verification](https://github.com/happynear/FaceVerification)

[dlib-jitter](https://github.com/davisking/dlib/blob/cbd187fb6109d21406f6a76bb0e9aa0689b1e54a/examples/dnn_face_recognition_ex.cpp)

[dlib-face-verification-blog](http://blog.dlib.net)












